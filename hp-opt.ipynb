{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hp-opt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-venkatesh/train-synth-audio-seg/blob/main/hp-opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEF2proepH9h"
      },
      "source": [
        "!pip install numba==0.48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iQeu-LxPaeV"
      },
      "source": [
        "!pip install sed_eval\n",
        "!pip install librosa==0.7.2\n",
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIoY53heKet"
      },
      "source": [
        "!pip install keras-tcn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JJ66pwzrOR4"
      },
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwmWHMfWPYJq"
      },
      "source": [
        "# !pip uninstall keras-tuner -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3r5EH09PJ2p"
      },
      "source": [
        "# !git clone https://github.com/satvik-venkatesh/keras-tuner.git\r\n",
        "# #cd keras-tuner\r\n",
        "# !pip install keras-tuner/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAr0CO_wC543"
      },
      "source": [
        "import numpy as np\n",
        "import IPython\n",
        "import math\n",
        "import glob\n",
        "import sed_eval\n",
        "import dcase_util\n",
        "import pickle\n",
        "import os\n",
        "import shutil\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import Input, Model\n",
        "from tcn import TCN\n",
        "from kerastuner import HyperModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMtmlH9RlyNl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2muBoiK7fMKP"
      },
      "source": [
        "\"\"\"\n",
        "Mount Google Drive into Colab.\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpjtJhW3kRPA"
      },
      "source": [
        "\"\"\"\n",
        "Extract artificial data into the 'train data' folder.\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "\n",
        "for i in range(0, 8):\n",
        "  zip_name = \"/content/drive/My Drive/Data Synthesis/Train - d_\" + str(i + 1) + \".zip\"\n",
        "  with ZipFile(zip_name, 'r') as zip:\n",
        "    zip.extractall('train data')\n",
        "    print(\"Extracted all sound files into the folder {}\".format(i + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZT-bvwtnY-9"
      },
      "source": [
        "\"\"\"\n",
        "Extracting Train data (if you have annotated real-world data)\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "zip_name = \"/content/drive/My Drive/Data Synthesis/Real-Train.zip\"\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('train data')\n",
        "  print(\"Extracted all sound files into the folder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuftbJJSC-oZ"
      },
      "source": [
        "\"\"\"\n",
        "Extracting Real-world Val data\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "zip_name = \"/content/drive/My Drive/Data Synthesis/Val - d.zip\"\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('validation data')\n",
        "  print(\"Extracted all sound files into the folder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PTvEOVZlteC"
      },
      "source": [
        "def to_seg_by_class(events, n_frames = 802):\n",
        "  labels = np.zeros((n_frames, 2), dtype=np.float32)\n",
        "\n",
        "  for e in events:\n",
        "    t1 = float(e[0])\n",
        "    t1 = int(t1 / 220 * 22050)\n",
        "    t2 = float(e[1])\n",
        "    t2 = int(t2 / 220 * 22050)\n",
        "\n",
        "    if e[2] == 'speech':\n",
        "      labels[t1:t2, 0] = 1\n",
        "    elif e[2] == 'music':\n",
        "      labels[t1:t2, 1] = 1\n",
        "  \n",
        "  return labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqrFP6VxEEJ"
      },
      "source": [
        "\"\"\"\n",
        "Convert the pickle files to npy\n",
        "\"\"\"\n",
        "\n",
        "labels = glob.glob(\"/content/train data/**/mel-id-label-[0-9]*.pickle\", recursive=True)\n",
        "\n",
        "for ll in labels:\n",
        "  with open(ll, 'rb') as f:\n",
        "    n = pickle.load(f)\n",
        "  n2 = to_seg_by_class(n)\n",
        "  np.save(ll.replace(\".pickle\", \".npy\"), n2)\n",
        "\n",
        "\n",
        "labels = glob.glob(\"/content/validation data/**/mel-id-label-[0-9]*.pickle\", recursive=True)\n",
        "\n",
        "for ll in labels:\n",
        "  with open(ll, 'rb') as f:\n",
        "    n = pickle.load(f)\n",
        "  n2 = to_seg_by_class(n)\n",
        "  np.save(ll.replace(\".pickle\", \".npy\"), n2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ8m-5Kl7JAb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "class DataGenerator(tf.compat.v2.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_examples, batch_size=128, dim=(1, ),\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        print(\"Constructor called!!!\")\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_examples = list_examples\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        #print(\"The self.list_examples is {}\".format(self.list_examples))\n",
        "        return int(np.floor(len(self.list_examples) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_examples[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      self.indexes = np.arange(len(self.list_examples))\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # 'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # # Initialization\n",
        "\n",
        "        X = np.empty([self.batch_size, 802, 80], dtype=np.float32)\n",
        "        y = np.empty([self.batch_size, 802, 2], dtype=np.float32)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "          # Store sample\n",
        "\n",
        "          xx = np.load(ID[0])\n",
        "          X[i, :, :] = xx\n",
        "\n",
        "          # Store class\n",
        "          yy = np.load(ID[1])\n",
        "                    \n",
        "          y[i, :, :] = yy\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kh1_gI_vKMO"
      },
      "source": [
        "import re\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "    \n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3diPkTbs-W"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\"\"\"\n",
        "Load the individual numpy arrays into partition\n",
        "\"\"\"\n",
        "data = glob.glob(\"/content/train data/**/mel-id-[0-9]*.npy\", recursive=True) # + glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "#data = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/train data/**/mel-id-label-[0-9]*.npy\", recursive=True) #+ glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "#labels = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "train_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(train_examples)\n",
        "\n",
        "partition = {}\n",
        "partition['train'] = train_examples\n",
        "\n",
        "random.shuffle(partition['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sianBGv5hkr0"
      },
      "source": [
        "\"\"\"\n",
        "This loads data for the validation set.\n",
        "\"\"\"\n",
        "import glob\n",
        "import random\n",
        "\n",
        "data = glob.glob(\"/content/validation data/**/mel-id-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/validation data/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "validation_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(validation_examples)\n",
        "\n",
        "partition['validation'] = validation_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ72mWisst9U"
      },
      "source": [
        "len(partition['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzW248zAFTC"
      },
      "source": [
        "# Parameters\n",
        "params = {'dim': (1, ),\n",
        "          'batch_size': 32,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], **params)\n",
        "validation_generator = DataGenerator(partition['validation'], **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNqxZRSr0gP"
      },
      "source": [
        "class SpeechF1(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='speech_f1', **kwargs):\n",
        "    super(SpeechF1, self).__init__(name=name, **kwargs)\n",
        "    self.tp = self.add_weight(name='true_positive', initializer='zeros')\n",
        "    self.fp = self.add_weight(name='false_positive', initializer='zeros')\n",
        "    self.tn = self.add_weight(name='true_negative', initializer='zeros')\n",
        "    self.fn = self.add_weight(name='false_negative', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "    threshold = tf.constant([0.5])\n",
        "\n",
        "    binary_true = y_true[:, :, 0]\n",
        "    binary_pred = y_pred[:, :, 0]\n",
        "\n",
        "    binary_true = tf.greater_equal(binary_true, threshold)\n",
        "    binary_pred = tf.greater_equal(binary_pred, threshold)\n",
        "\n",
        "    tp = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, True)), dtype = np.float32)\n",
        "    fp = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, True)), dtype = np.float32)\n",
        "    tn = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, False)), dtype = np.float32)\n",
        "    fn = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, False)), dtype = np.float32)\n",
        "\n",
        "    self.tp.assign_add(tf.reduce_sum(tp, axis = None))\n",
        "    self.fp.assign_add(tf.reduce_sum(fp, axis = None))\n",
        "    self.tn.assign_add(tf.reduce_sum(tn, axis = None))\n",
        "    self.fn.assign_add(tf.reduce_sum(fn, axis = None))\n",
        "\n",
        "  def result(self):\n",
        "    binary_f1 = self.tp / (self.tp +  0.5 * (self.fp + self.fn))\n",
        "    return binary_f1\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.tp.assign(0)\n",
        "    self.fp.assign(0)\n",
        "    self.tn.assign(0)\n",
        "    self.fn.assign(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzT1FpeE1HGC"
      },
      "source": [
        "class MusicF1(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='music_f1', **kwargs):\n",
        "    super(MusicF1, self).__init__(name=name, **kwargs)\n",
        "    self.tp = self.add_weight(name='true_positive', initializer='zeros')\n",
        "    self.fp = self.add_weight(name='false_positive', initializer='zeros')\n",
        "    self.tn = self.add_weight(name='true_negative', initializer='zeros')\n",
        "    self.fn = self.add_weight(name='false_negative', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "    threshold = tf.constant([0.5])\n",
        "\n",
        "    binary_true = y_true[:, :, 1]\n",
        "    binary_pred = y_pred[:, :, 1]\n",
        "\n",
        "    binary_true = tf.greater_equal(binary_true, threshold)\n",
        "    binary_pred = tf.greater_equal(binary_pred, threshold)\n",
        "\n",
        "    tp = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, True)), dtype = np.float32)\n",
        "    fp = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, True)), dtype = np.float32)\n",
        "    tn = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, False)), dtype = np.float32)\n",
        "    fn = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, False)), dtype = np.float32)\n",
        "\n",
        "    self.tp.assign_add(tf.reduce_sum(tp, axis = None))\n",
        "    self.fp.assign_add(tf.reduce_sum(fp, axis = None))\n",
        "    self.tn.assign_add(tf.reduce_sum(tn, axis = None))\n",
        "    self.fn.assign_add(tf.reduce_sum(fn, axis = None))\n",
        "\n",
        "  def result(self):\n",
        "    binary_f1 = self.tp / (self.tp +  0.5 * (self.fp + self.fn))\n",
        "    return binary_f1\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.tp.assign(0)\n",
        "    self.fp.assign(0)\n",
        "    self.tn.assign(0)\n",
        "    self.fn.assign(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fncNqYl7wVx"
      },
      "source": [
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=2500,\n",
        "    decay_rate=0.84,\n",
        "    staircase=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww07a2_OIiUs"
      },
      "source": [
        "\n",
        "import os\n",
        "class MyCustomCallback_3(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, model_dir, patience=0):\n",
        "    super(MyCustomCallback_3, self).__init__()\n",
        "    self.patience = patience\n",
        "    # best_weights to store the weights at which the minimum loss occurs.\n",
        "    self.best_weights = None\n",
        "    self.model_best_path = os.path.join(model_dir, 'model-best.h5')\n",
        "    self.model_last_path = os.path.join(model_dir, 'model-last-epoch.h5')\n",
        "    self.custom_params = {\"best_loss\":np.inf, \"last_epoch\":0, \"best_binary_accuracy\":0}\n",
        "    \n",
        "    self.custom_params_path = os.path.join(model_dir, 'custom_params.pickle')\n",
        "    if os.path.isfile(self.custom_params_path):\n",
        "      with open(self.custom_params_path, 'rb') as f:\n",
        "        self.custom_params = pickle.load(f)\n",
        "      best_model = tf.keras.models.load_model(self.model_best_path, custom_objects={ \n",
        "                  'binary_acc':binary_acc, 'TCN':TCN(), 'SpeechF1':SpeechF1(), 'MusicF1':MusicF1()})\n",
        "      self.best_weights = best_model.get_weights()\n",
        "\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    # The number of epoch it has waited when loss is no longer minimum.\n",
        "    self.wait = 0\n",
        "    # The epoch the training stops at.\n",
        "    self.stopped_epoch = 0\n",
        "    # Initialize the best F1 as 0.0.\n",
        "    self.is_impatient = False\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if not self.is_impatient:\n",
        "      print(\"Restoring model weights from the end of the best epoch.\")\n",
        "      self.model.set_weights(self.best_weights)\n",
        "      # temp_model_path = self.model_path.replace(\".h5\", \"_temp.h5\")\n",
        "      #os.remove(temp_model_path)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current_val_loss = logs.get(\"val_loss\")\n",
        "    current_binary_accuracy = logs.get(\"val_binary_accuracy\")\n",
        "    self.model.save(self.model_last_path)\n",
        "    self.custom_params[\"last_epoch\"] = self.custom_params[\"last_epoch\"] + 1\n",
        "\n",
        "    if current_binary_accuracy > self.custom_params['best_binary_accuracy']:\n",
        "      self.custom_params['best_binary_accuracy'] = current_binary_accuracy\n",
        "      self.custom_params['best_loss'] = current_val_loss\n",
        "      self.wait = 0\n",
        "      self.best_weights = self.model.get_weights()\n",
        "      self.model.save(self.model_best_path)\n",
        "\n",
        "    else:\n",
        "        self.wait += 1\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.is_impatient = True\n",
        "            self.model.stop_training = True\n",
        "            print(\"Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)\n",
        "            #os.remove(temp_model_path)\n",
        "    with open(self.custom_params_path, 'wb') as f:\n",
        "      pickle.dump(self.custom_params, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvkDQ3klMOHt"
      },
      "source": [
        "\"\"\"\r\n",
        "The below class loads the hypermodel for any of the Neural Network architectures --- CNN, B-LSTM, B-GRU, ncTCN, and CRNN.\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "class MyHyperModel(HyperModel):\r\n",
        "\r\n",
        "    def __init__(self, model_architecture):\r\n",
        "      self.model_architecture = model_architecture\r\n",
        "\r\n",
        "    def build(self, hp):\r\n",
        "\r\n",
        "      if self.model_architecture == \"CNN\":\r\n",
        "        mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\r\n",
        "        X = mel_input\r\n",
        "\r\n",
        "        X = tf.keras.layers.Reshape((802, 80, 1))(X)\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_conv_layers', 1, 4)):\r\n",
        "          X = tf.keras.layers.Conv2D(filters=hp.Choice('filters_' + str(i), values = [16, 32, 64, 128]),\r\n",
        "                                    kernel_size=hp.Int('kernel_size_' + str(i), min_value = 3, max_value = 15, step = 2),\r\n",
        "                                    strides = 1,\r\n",
        "                                    padding='same')(X)\r\n",
        "\r\n",
        "          X = layers.BatchNormalization(axis = [-2, -1])(X)\r\n",
        "          X = tf.keras.layers.Activation('relu')(X)\r\n",
        "\r\n",
        "          X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\r\n",
        "\r\n",
        "        _, _, sx, sy = X.shape\r\n",
        "        X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\r\n",
        "\r\n",
        "        dropout_rate = hp.Float('fc_dropout', min_value = 0.0, max_value = 0.5, step = 0.05)\r\n",
        "        for i in range(hp.Int('num_fc_layers', 1, 4)):\r\n",
        "          X = layers.Dense(hp.Int('fc_units_' + str(i), min_value = 128, max_value = 1024, step = 128, default = 512), activation='relu')(X)\r\n",
        "\r\n",
        "          X = layers.Dropout(rate = dropout_rate)(X)\r\n",
        "\r\n",
        "        pred = layers.Dense(2, name=\"speech_and_music\", activation='sigmoid')(X)\r\n",
        "\r\n",
        "        model = keras.Model(inputs = [mel_input], outputs = [pred])\r\n",
        "\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\r\n",
        "            loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy()]\r\n",
        "        )\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "      elif self.model_architecture == \"B-LSTM\":\r\n",
        "        mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\r\n",
        "        X = mel_input\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_lstm_layers', 1, 4)):\r\n",
        "          X = layers.Bidirectional(layers.LSTM(hp.Int('lstm_units_' + str(i), min_value = 20, max_value = 260, step = 20),\r\n",
        "                                              return_sequences = True))(X)\r\n",
        "\r\n",
        "          X = layers.LayerNormalization()(X)    \r\n",
        "\r\n",
        "\r\n",
        "        pred = layers.Dense(2, name=\"speech_and_music\", activation='sigmoid')(X)\r\n",
        "\r\n",
        "        model = keras.Model(inputs = [mel_input], outputs = [pred])\r\n",
        "\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\r\n",
        "            loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy()]\r\n",
        "        )\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "\r\n",
        "      elif self.model_architecture == \"B-GRU\":\r\n",
        "        mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\r\n",
        "        X = mel_input\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_gru_layers', 1, 4)):\r\n",
        "          X = layers.Bidirectional(layers.GRU(hp.Int('gru_units_' + str(i), min_value = 20, max_value = 260, step = 20),\r\n",
        "                                              return_sequences = True))(X)\r\n",
        "\r\n",
        "          X = layers.LayerNormalization()(X)    \r\n",
        "\r\n",
        "\r\n",
        "        pred = layers.Dense(2, name=\"speech_and_music\", activation='sigmoid')(X)\r\n",
        "\r\n",
        "        model = keras.Model(inputs = [mel_input], outputs = [pred])\r\n",
        "\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\r\n",
        "            loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy()]\r\n",
        "        )\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "      elif self.model_architecture == \"ncTCN\":\r\n",
        "        mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\r\n",
        "        X = mel_input\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_tcn_layers', 1, 4)):\r\n",
        "          N_D = hp.Int('num_dilations_' + str(i), 1, 8)\r\n",
        "          dilations_list = [2 ** d for d in list(range(N_D + 1))]\r\n",
        "          X = TCN(nb_filters=hp.Choice('nb_filters_' + str(i), values = [16, 32]),\r\n",
        "                  kernel_size = hp.Int('kernel_size_' + str(i), min_value = 3, max_value = 19, step = 2),\r\n",
        "                  nb_stacks=hp.Int('num_stacks_' + str(i), 1, 10), dilations = dilations_list, padding='same',\r\n",
        "                  use_skip_connections=hp.Boolean('use_skip_connections_' + str(i)), activation = 'relu',\r\n",
        "                  use_layer_norm = True, return_sequences=True)(X)\r\n",
        "\r\n",
        "        X = Dense(2)(X)\r\n",
        "        pred = Activation('sigmoid')(X)\r\n",
        "\r\n",
        "        model = keras.Model(inputs = [mel_input], outputs = [pred])\r\n",
        "\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\r\n",
        "            loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy()])\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "\r\n",
        "      elif self.model_architecture == \"CRNN\":\r\n",
        "        mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\r\n",
        "        X = mel_input\r\n",
        "\r\n",
        "        X = tf.keras.layers.Reshape((802, 80, 1))(X)\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_conv_layers', 1, 4)):\r\n",
        "          X = tf.keras.layers.Conv2D(filters=hp.Choice('filters_' + str(i), values = [16, 32, 64, 128]),\r\n",
        "                                    kernel_size=hp.Int('kernel_size_' + str(i), min_value = 3, max_value = 15, step = 2),\r\n",
        "                                    strides = 1,\r\n",
        "                                    padding='same')(X)\r\n",
        "\r\n",
        "          X = tf.keras.layers.Activation('relu')(X)\r\n",
        "\r\n",
        "          X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\r\n",
        "\r\n",
        "          X = layers.LayerNormalization(axis = [-2, -1])(X)\r\n",
        "\r\n",
        "        _, _, sx, sy = X.shape\r\n",
        "        X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\r\n",
        "\r\n",
        "\r\n",
        "        for i in range(hp.Int('num_gru_layers', 1, 4)):\r\n",
        "          X = layers.Bidirectional(layers.GRU(hp.Int('gru_units_' + str(i), min_value = 20, max_value = 160, step = 20),\r\n",
        "                                              return_sequences = True))(X)\r\n",
        "\r\n",
        "          X = layers.LayerNormalization()(X)    \r\n",
        "\r\n",
        "        pred = layers.Dense(2, name=\"speech_and_music\", activation='sigmoid')(X)\r\n",
        "\r\n",
        "        model = keras.Model(inputs = [mel_input], outputs = [pred])\r\n",
        "\r\n",
        "        model.compile(\r\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\r\n",
        "            loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy()]\r\n",
        "        )\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "      else:\r\n",
        "        print(\"Invalid model architecture!!\")\r\n",
        "        return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGUCOys_r_W1"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVTQY-DuQOVU"
      },
      "source": [
        "random.seed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYG3T4YmsBUW"
      },
      "source": [
        "\"\"\"\n",
        "Possible model architectures are CNN, B-LSTM, B-GRU, ncTCN, and CRNN.\n",
        "\"\"\"\n",
        "tuner = kt.Hyperband(MyHyperModel(model_architecture=\"CRNN\"),\n",
        "                     objective = 'val_binary_accuracy', \n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = '/content/drive/My Drive/Hp opt',\n",
        "                     project_name = 'CRNN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INafYFHotexA"
      },
      "source": [
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUJLB_rCtUsG"
      },
      "source": [
        "tuner.search(training_generator, epochs = 10, validation_data = validation_generator, callbacks = [ClearTrainingOutput()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms_Z9LyioFGu"
      },
      "source": [
        "print(\"Tuning is complete!!!\")\n",
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "print (\"Current date and time : \")\n",
        "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjR7Y3s0rpP"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29bX3WZ8FNhh"
      },
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJwLJW8dITrL"
      },
      "source": [
        "best_hps.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOPibtKOF8Ij"
      },
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdvC6n60Fq6I"
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSQeo0tMQtc"
      },
      "source": [
        "best_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy(), SpeechF1(), MusicF1()] #, 'categorical_accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Precision(class_id=1), tf.keras.metrics.Recall(class_id=0), tf.keras.metrics.Recall(class_id=1)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5GBqRyRMUsF"
      },
      "source": [
        "best_model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTfdNSJJImB"
      },
      "source": [
        "\"\"\"\n",
        "Create a fresh model from the best set of hyperparameters.\n",
        "\"\"\"\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "model = tuner.hypermodel.build(best_hp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7ZVPx_-Ko5f"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=[tf.keras.losses.BinaryCrossentropy()], metrics=[tf.keras.metrics.BinaryAccuracy(), SpeechF1(), MusicF1()] #, 'categorical_accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Precision(class_id=1), tf.keras.metrics.Recall(class_id=0), tf.keras.metrics.Recall(class_id=1)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgQo2ty6qBsU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-e6UfJnlIvM"
      },
      "source": [
        "\"\"\"\r\n",
        "Create a directory to train the model for an extended number epochs\r\n",
        "\"\"\"\r\n",
        "os.mkdir(\"/content/drive/MyDrive/Models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdF9VFqOI8Xv"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "root_dir = \"/content/drive/MyDrive/Models\"\n",
        "model_name = 'CRNN'\n",
        "model_dir = os.path.join(root_dir, model_name)\n",
        "\n",
        "try: \n",
        "    os.mkdir(model_dir) \n",
        "except OSError as error: \n",
        "    pass  \n",
        "\n",
        "%load_ext tensorboard\n",
        "import datetime, os\n",
        "logdir = os.path.join(root_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(os.path.join(root_dir, model_name), histogram_freq=1)\n",
        "\n",
        "%tensorboard --logdir \"{logdir}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4fL8Qbf2WpF"
      },
      "source": [
        "initial_epoch = 0\n",
        "p = os.path.join(model_dir, 'custom_params.pickle')\n",
        "if os.path.isfile(p):\n",
        "  print(\"Entered if!!!\")\n",
        "  with open(p, 'rb') as f:\n",
        "    custom_params = pickle.load(f)\n",
        "    last_epoch = custom_params['last_epoch']\n",
        "    initial_epoch = last_epoch\n",
        "  model_path = os.path.join(model_dir, 'model-last-epoch.h5')\n",
        "  print(model_path)\n",
        "  model = tf.keras.models.load_model(model_path, custom_objects={ \n",
        "                  'binary_acc':binary_acc, 'TCN':TCN(), 'SpeechF1':SpeechF1(), 'MusicF1':MusicF1()})\n",
        "  # model.load_weights(model_path)\n",
        "  model.fit(training_generator, validation_data=validation_generator, epochs=300, initial_epoch = initial_epoch, \n",
        "            callbacks=[MyCustomCallback_3(model_dir, patience=20), tensorboard_callback], verbose=2)\n",
        "\n",
        "else:\n",
        "  print(\"Entered else!!!\")\n",
        "\n",
        "  model.fit(training_generator, validation_data=validation_generator, epochs=300,\n",
        "            callbacks=[MyCustomCallback_3(model_dir, patience=20), tensorboard_callback], verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-m1Hya3o9F"
      },
      "source": [
        "print(\"Training is complete!!!\")\r\n",
        "import datetime\r\n",
        "now = datetime.datetime.now()\r\n",
        "print (\"Current date and time : \")\r\n",
        "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}