{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mk-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrHt+KKqxSmIzLrJPM2VLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-venkatesh/train-synth-audio-seg/blob/main/mk-prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk1HtQjLdM6y"
      },
      "source": [
        "Please note that the pre-trained models are for non-commercial use only. It is under the [Create Commons Attribution-NonCommercial-ShareAlike-3.0 Unported (CC BY-NC-SA 3.0) license](https://creativecommons.org/licenses/by-nc-sa/3.0/).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiU4n9kbc-jO",
        "outputId": "23cb065e-9f90-489b-873e-638dfb341aee"
      },
      "source": [
        "!pip install numba==0.48"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba==0.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/dc/5ce4a94d98e8a31cab21b150e23ca2f09a7dd354c06a69f71801ecd890db/numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (53.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (1.19.5)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/10/d02c0ac683fc47ecda3426249509cf771d748b6a2c0e9d5ebbee76a7b80a/llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.2MB/s \n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pynndescent 0.5.2 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYI9IAnkdaBa",
        "outputId": "694970b9-5062-42c5-99f9-02d71a59f750"
      },
      "source": [
        "!pip install soundfile==0.10.3.post1\r\n",
        "!sudo apt-get install sox\r\n",
        "!pip install sed_eval\r\n",
        "!pip install librosa==0.7.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1) (2.20)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 sox\n",
            "0 upgraded, 8 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 760 kB of archives.\n",
            "After this operation, 6,717 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.1 [226 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.1 [10.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.1 [32.1 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.1 [101 kB]\n",
            "Fetched 760 kB in 1s (617 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 149406 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Collecting sed_eval\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/b2/55591da46753ad1f1d375f5a0d1e12728ae9bf7270ecf47ff7fe902a4274/sed_eval-0.2.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from sed_eval) (1.19.5)\n",
            "Collecting dcase_util>=0.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/3e/e792e2298c4ed2649344846e13a3db722c0eea4b3b2216d29f1ec039de48/dcase_util-0.2.16.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.2.2)\n",
            "Requirement already satisfied: librosa>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.15.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.16.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.10.3.post1)\n",
            "Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.13)\n",
            "Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (4.41.1)\n",
            "Requirement already satisfied: pydot-ng>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.0.0)\n",
            "Collecting validators>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Collecting python-magic>=0.4.13\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/7c/1d1d4bdda29bfec662b9b50951dee2dddf7747d3cbf7777f3d1c63372bd0/python_magic-0.4.22-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (0.10.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.48.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.0.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (1.14.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.31.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (20.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (2.20)\n",
            "Building wheels for collected packages: sed-eval, dcase-util\n",
            "  Building wheel for sed-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sed-eval: filename=sed_eval-0.2.1-cp37-none-any.whl size=26124 sha256=7e288f8302777124b7c1db85c38579770ee606830f481fb0da89b769975b090a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/72/5d/5fc941f98c583ce9d8adee7f13e24b46459aeded4125f9c369\n",
            "  Building wheel for dcase-util (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dcase-util: filename=dcase_util-0.2.16-cp37-none-any.whl size=2124351 sha256=5d329f1d6bc1087b228799f344f6c3f55f15ac289251942e1ff553495ef30996\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/46/3b/1f9de1bd2ddfb9868bd7bf1cc38e83e42660fdfaacc6419bd0\n",
            "Successfully built sed-eval dcase-util\n",
            "Installing collected packages: validators, python-magic, dcase-util, sed-eval\n",
            "Successfully installed dcase-util-0.2.16 python-magic-0.4.22 sed-eval-0.2.1 validators-0.18.2\n",
            "Collecting librosa==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (0.48.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2) (0.10.3.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.7.2) (53.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-cp37-none-any.whl size=1612885 sha256=4e10a7974a0292556cb44a52d16823925c879c78c8b9e79ec3bafc8f4db89ac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
            "Successfully built librosa\n",
            "Installing collected packages: librosa\n",
            "  Found existing installation: librosa 0.8.0\n",
            "    Uninstalling librosa-0.8.0:\n",
            "      Successfully uninstalled librosa-0.8.0\n",
            "Successfully installed librosa-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYVAJ24gdZa1",
        "outputId": "95bf9cfd-6a4c-44a1-b336-21388012e10b"
      },
      "source": [
        "!git clone https://github.com/satvik-venkatesh/train-synth-audio-seg.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'train-synth-audio-seg'...\n",
            "remote: Enumerating objects: 574, done.\u001b[K\n",
            "remote: Total 574 (delta 0), reused 0 (delta 0), pack-reused 574\u001b[K\n",
            "Receiving objects: 100% (574/574), 380.20 MiB | 27.67 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n",
            "Checking out files: 100% (375/375), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzXA43yd2j-"
      },
      "source": [
        "import soundfile as sf\r\n",
        "import numpy as np\r\n",
        "from shutil import copyfile\r\n",
        "import os\r\n",
        "import librosa\r\n",
        "import tensorflow as tf\r\n",
        "import math\r\n",
        "import sed_eval\r\n",
        "import dcase_util\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "import glob\r\n",
        "from subprocess import Popen, PIPE"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ9J12x7ZHNu"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJEnwns-nduO"
      },
      "source": [
        "def remove_silence(sound):\n",
        "  \"\"\"\n",
        "  The procedure to remove silence from audio tracks is copied from the Lemaire et al. (2019) github repository.\n",
        "  \"\"\"\n",
        "  temp_file = sound.replace('.wav', '_t.wav').replace('.WAV', '_t.WAV')\n",
        "  command = \"sox \" + sound + \" \" + temp_file + \" silence -l 1 0.1 1% -1 0.1 1%\"\n",
        "  p = Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
        "  output, err = p.communicate()\n",
        "  copyfile(temp_file, sound)\n",
        "  os.remove(temp_file)\n",
        "\n",
        "\n",
        "def get_sound_segments(sound_list, segment_size = 1.0, sampling_rate = 22050.0):\n",
        "  # Load the first sound file.\n",
        "  #remove_silence(sound_list[0])\n",
        "  in_signal, in_sr = sf.read(sound_list[0], dtype='float32')\n",
        "  print(\"in_signal.dtype is {}\".format(in_signal.dtype))\n",
        "\n",
        "  # Resample the audio file.\n",
        "  in_signal_22k = librosa.resample(in_signal, orig_sr=in_sr, target_sr=sampling_rate)\n",
        "  in_signal = np.copy(in_signal_22k)\n",
        "\n",
        "  # Calculate segment size in samples and no of segments\n",
        "  ss = int (sampling_rate * segment_size)\n",
        "  n = int(in_signal.shape[0] / ss)\n",
        "\n",
        "  seg0 = np.reshape(in_signal[0:n * ss], (n, -1))\n",
        "\n",
        "  seg = np.copy(seg0)\n",
        "  # Extract embeddings from remaining files.\n",
        "  for s in sound_list[1:]:\n",
        "    #remove_silence(s)\n",
        "    in_signal, in_sr = sf.read(s)\n",
        "    \n",
        "    # Resample the audio file.\n",
        "    in_signal_22k = librosa.resample(in_signal, orig_sr=in_sr, target_sr=sampling_rate)\n",
        "    in_signal = np.copy(in_signal_22k)\n",
        "    \n",
        "    # Calculate segment size in samples and no of segments\n",
        "    ss = int (sampling_rate * segment_size)\n",
        "    n = int(in_signal.shape[0] / ss)\n",
        "\n",
        "    seg_s = np.reshape(in_signal[0:n * ss], (n, -1))\n",
        "\n",
        "    seg = np.concatenate((seg, seg_s), axis = 0) #em concatenates all the values of embeddings.\n",
        "\n",
        "  return seg \n",
        "\n",
        "\"\"\"\n",
        "A function to extract mel spectrograms.\n",
        "\"\"\"\n",
        "def extract_mel_spec(segments, sr = 22050, hop_length = 220, n_fft = 1024): \n",
        "  # `segments_mel_spec` contains the extracted mel spectrograms.\n",
        "  \n",
        "\n",
        "  # Calculate mel spectrogram of first segment.\n",
        "  s0 = segments[0, :]\n",
        "  mel_spec0 = librosa.feature.melspectrogram(y=s0, sr=sr, hop_length=hop_length, n_fft=n_fft, fmin=64, fmax=8000, n_mels=80)\n",
        "  print('mel_spec0.dtype is {}'.format(mel_spec0.dtype))\n",
        "  # D = librosa.stft(s0, hop_length=hop_length, n_fft=n_fft)\n",
        "  # magnitude, phase = librosa.magphase(D)\n",
        "  # print(\"magnitude.shape is {}\".format(magnitude.shape ))\n",
        "  # print(\"phase.shape is {}\".format(phase.shape ))\n",
        "  # ang_phase = np.angle(phase)\n",
        "  # print(\"ang_phase.shape is {}\".format(ang_phase.shape))\n",
        "  # mel_spec0 = np.concatenate((mel_spec0, ang_phase), axis = 0)\n",
        "\n",
        "  (m, _) = segments.shape\n",
        "  (n, o) = mel_spec0.shape\n",
        "  segments_mel_spec = np.zeros((m, n, o), dtype='float32')\n",
        "  segments_mel_spec[0, :, :] = mel_spec0\n",
        "\n",
        "  for i in range(1, m):\n",
        "    s = segments[i, :]\n",
        "    mel_spec = librosa.feature.melspectrogram(y=s, sr=sr, hop_length=hop_length, n_fft=n_fft, n_mels=80)\n",
        "    # D = librosa.stft(s, hop_length=hop_length, n_fft=n_fft)\n",
        "    # magnitude, phase = librosa.magphase(D)\n",
        "    # ang_phase = np.angle(phase)\n",
        "    # mel_spec = np.concatenate((mel_spec, ang_phase), axis = 0)\n",
        "    segments_mel_spec[i, :, :] = mel_spec\n",
        "\n",
        "  return segments_mel_spec\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This function was copied from Lemaire et al. 2019. \n",
        "\"\"\"\n",
        "\n",
        "def smooth_output(output, min_speech=1.3, min_music=3.4, max_silence_speech=0.4, max_silence_music=0.6):\n",
        "    duration_frame = 220 / 22050\n",
        "    n_frame = output.shape[1]\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if output[0, i] == 1:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= max_silence_speech:\n",
        "                    output[0, start_speech:i] = 1\n",
        "\n",
        "            start_speech = i\n",
        "\n",
        "        if output[1, i] == 1:\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= max_silence_music:\n",
        "                    output[1, start_music:i] = 1\n",
        "\n",
        "            start_music = i\n",
        "\n",
        "    start_music = -1000\n",
        "    start_speech = -1000\n",
        "\n",
        "    for i in range(n_frame):\n",
        "        if i != n_frame - 1:\n",
        "            if output[0, i] == 0:\n",
        "                if i - start_speech > 1:\n",
        "                    if (i - start_speech) * duration_frame <= min_speech:\n",
        "                        output[0, start_speech:i] = 0\n",
        "\n",
        "                start_speech = i\n",
        "\n",
        "            if output[1, i] == 0:\n",
        "                if i - start_music > 1:\n",
        "                    if (i - start_music) * duration_frame <= min_music:\n",
        "                        output[1, start_music:i] = 0\n",
        "\n",
        "                start_music = i\n",
        "        else:\n",
        "            if i - start_speech > 1:\n",
        "                if (i - start_speech) * duration_frame <= min_speech:\n",
        "                    output[0, start_speech:i + 1] = 0\n",
        "\n",
        "            if i - start_music > 1:\n",
        "                if (i - start_music) * duration_frame <= min_music:\n",
        "                    output[1, start_music:i + 1] = 0\n",
        "\n",
        "    return output\n",
        "\n",
        "\"\"\"\n",
        "This function converts the predictions made by the neural network into a format that is understood by sed_eval.\n",
        "\"\"\"\n",
        "\n",
        "def preds_to_se(p, audio_clip_length = 8.0):\n",
        "  start_speech = -100\n",
        "  start_music = -100\n",
        "  stop_speech = -100\n",
        "  stop_music = -100\n",
        "\n",
        "  audio_events = []\n",
        "\n",
        "  n_frames = p.shape[0]\n",
        "\n",
        "  if p[0, 0] == 1:\n",
        "    start_speech = 0\n",
        "  \n",
        "  if p[0, 1] == 1:\n",
        "    start_music = 0\n",
        "\n",
        "  for i in range(n_frames - 1):\n",
        "    if p[i, 0] == 0 and p[i + 1, 0] == 1:\n",
        "      start_speech = i + 1\n",
        "\n",
        "    elif p[i, 0] == 1 and p[i + 1, 0] == 0:\n",
        "      stop_speech = i\n",
        "      start_time = frames_to_time(start_speech)\n",
        "      stop_time = frames_to_time(stop_speech)\n",
        "      audio_events.append((start_time, stop_time, \"speech\"))\n",
        "      start_speech = -100\n",
        "      stop_speech = -100\n",
        "\n",
        "    if p[i, 1] == 0 and p[i + 1, 1] == 1:\n",
        "      start_music = i + 1\n",
        "    elif p[i, 1] == 1 and p[i + 1, 1] == 0:\n",
        "      stop_music = i\n",
        "      start_time = frames_to_time(start_music)\n",
        "      stop_time = frames_to_time(stop_music)      \n",
        "      audio_events.append((start_time, stop_time, \"music\"))\n",
        "      start_music = -100\n",
        "      stop_music = -100\n",
        "\n",
        "  if start_speech != -100:\n",
        "    start_time = frames_to_time(start_speech)\n",
        "    stop_time = audio_clip_length\n",
        "    audio_events.append((start_time, stop_time, \"speech\"))\n",
        "    start_speech = -100\n",
        "    stop_speech = -100\n",
        "\n",
        "  if start_music != -100:\n",
        "    start_time = frames_to_time(start_music)\n",
        "    stop_time = audio_clip_length\n",
        "    audio_events.append((start_time, stop_time, \"music\"))\n",
        "    start_music = -100\n",
        "    stop_music = -100\n",
        "\n",
        "  audio_events.sort(key = lambda x: x[0]) \n",
        "  return audio_events\n",
        "\n",
        "def frames_to_time(f, sr = 22050.0, hop_size = 220):\n",
        "  return f * hop_size / sr\n",
        "\n",
        "def get_log_melspectrogram(audio, sr = 22050, hop_length = 220, n_fft = 1024, n_mels = 80, fmin = 64, fmax = 8000):\n",
        "    \"\"\"Return the log-scaled Mel bands of an audio signal.\"\"\"\n",
        "    bands = librosa.feature.melspectrogram(\n",
        "        y=audio, sr=sr, hop_length=hop_length, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax, dtype=np.float32)\n",
        "    return librosa.core.power_to_db(bands, amin=1e-7)\n",
        "\n",
        "def mk_preds_ens(audio_path, hop_size = 6.0, discard = 1.0, win_length = 8.0, sampling_rate = 22050):\n",
        "  in_signal, in_sr = sf.read(audio_path)\n",
        "\n",
        "  # Convert to mono if needed.\n",
        "  if (in_signal.ndim > 1):\n",
        "    in_signal_mono = librosa.to_mono(in_signal.T)\n",
        "    in_signal = np.copy(in_signal_mono)\n",
        "    \n",
        "  # Resample the audio file.\n",
        "  in_signal_22k = librosa.resample(in_signal, orig_sr=in_sr, target_sr=sampling_rate)\n",
        "  in_signal = np.copy(in_signal_22k)\n",
        "\n",
        "  # Pad the input signal if it is shorter than 8 s.\n",
        "  if in_signal.shape[0] < int(8.0 * sampling_rate):\n",
        "  \tpad_signal = np.zeros((int(8.0 * sampling_rate)))\n",
        "  \tpad_signal[:in_signal.shape[0]] = in_signal\n",
        "  \tin_signal = np.copy(pad_signal)\n",
        "\n",
        "\n",
        "  audio_clip_length_samples = in_signal.shape[0]\n",
        "  # print('audio_clip_length_samples is {}'.format(audio_clip_length_samples))\n",
        "\n",
        "  #hop_size_samples = int(hop_size * sampling_rate)\n",
        "  hop_size_samples = 220 * 602 - 1\n",
        "\n",
        "  #win_length_samples = int(win_length * sampling_rate)\n",
        "  win_length_samples = 220 * 802 - 1\n",
        "\n",
        "  n_preds = int(math.ceil((audio_clip_length_samples - win_length_samples) / hop_size_samples)) + 1\n",
        "  print(n_preds)\n",
        "\n",
        "  #print('n_preds is {}'.format(n_preds))\n",
        "\n",
        "  in_signal_pad = np.zeros((n_preds * hop_size_samples + 200 * 220))\n",
        "\n",
        "  #print('in_signal_pad.shape is {}'.format(in_signal_pad.shape))\n",
        "\n",
        "  in_signal_pad[0:audio_clip_length_samples] = in_signal\n",
        "\n",
        "  preds = np.zeros((n_preds, 802, 2))\n",
        "  mss_in = np.zeros((n_preds, 802, 80))\n",
        "\n",
        "  for i in range(n_preds):\n",
        "    seg = in_signal_pad[i * hop_size_samples:(i * hop_size_samples) + win_length_samples]\n",
        "    #print('seg.shape is {}'.format(seg.shape))\n",
        "    seg = librosa.util.normalize(seg)\n",
        "\n",
        "    mss = get_log_melspectrogram(seg)\n",
        "    M = mss.T\n",
        "    mss_in[i, :, :] = M\n",
        "\n",
        "  yhats = [model.predict(mss_in) for model in models]\n",
        "  yhats = np.array(yhats)\n",
        "  # sum across ensembles\n",
        "  summed = np.mean(yhats, axis=0)\n",
        "\n",
        "  preds = (summed >= (0.5, 0.5)).astype(np.float)\n",
        "  #p = cat_to_multi(p)\n",
        "\n",
        "  # preds[i, :, :] = p[0]\n",
        "\n",
        "  #discard_frames = 100\n",
        "  #oa_preds = np.zeros((, 128)) # overall predictions\n",
        "\n",
        "  preds_mid = np.copy(preds[1:-1, 100:702, :])\n",
        "\n",
        "  #print(\"preds_mid.shape is {}\".format(preds_mid.shape))\n",
        "\n",
        "  preds_mid_2 = preds_mid.reshape(-1, 2)\n",
        "\n",
        "  if preds.shape[0] > 1:\n",
        "    oa_preds = preds[0, 0:702, :] # oa stands for overall predictions\n",
        "\n",
        "  else:\n",
        "    oa_preds = preds[0, 0:802, :] # oa stands for overall predictions\n",
        "\n",
        "  oa_preds = np.concatenate((oa_preds, preds_mid_2), axis = 0)\n",
        "\n",
        "  if preds.shape[0] > 1:\n",
        "    oa_preds = np.concatenate((oa_preds, preds[-1, 100:, :]), axis = 0)\n",
        "\n",
        "  return oa_preds"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSqj4wTUeKYH"
      },
      "source": [
        "# Custom Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvxu1jGeeM1g"
      },
      "source": [
        "\"\"\"\r\n",
        "Custom Metrics\r\n",
        "\"\"\"\r\n",
        "class SpeechF1(tf.keras.metrics.Metric):\r\n",
        "\r\n",
        "  def __init__(self, name='speech_f1', **kwargs):\r\n",
        "    super(SpeechF1, self).__init__(name=name, **kwargs)\r\n",
        "    self.tp = self.add_weight(name='true_positive', initializer='zeros')\r\n",
        "    self.fp = self.add_weight(name='false_positive', initializer='zeros')\r\n",
        "    self.tn = self.add_weight(name='true_negative', initializer='zeros')\r\n",
        "    self.fn = self.add_weight(name='false_negative', initializer='zeros')\r\n",
        "\r\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
        "\r\n",
        "    threshold = tf.constant([0.5])\r\n",
        "\r\n",
        "    binary_true = y_true[:, :, 0]\r\n",
        "    binary_pred = y_pred[:, :, 0]\r\n",
        "\r\n",
        "    binary_true = tf.greater_equal(binary_true, threshold)\r\n",
        "    binary_pred = tf.greater_equal(binary_pred, threshold)\r\n",
        "\r\n",
        "    tp = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, True)), dtype = np.float32)\r\n",
        "    fp = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, True)), dtype = np.float32)\r\n",
        "    tn = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, False)), dtype = np.float32)\r\n",
        "    fn = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, False)), dtype = np.float32)\r\n",
        "\r\n",
        "    self.tp.assign_add(tf.reduce_sum(tp, axis = None))\r\n",
        "    self.fp.assign_add(tf.reduce_sum(fp, axis = None))\r\n",
        "    self.tn.assign_add(tf.reduce_sum(tn, axis = None))\r\n",
        "    self.fn.assign_add(tf.reduce_sum(fn, axis = None))\r\n",
        "\r\n",
        "  def result(self):\r\n",
        "    binary_f1 = self.tp / (self.tp +  0.5 * (self.fp + self.fn))\r\n",
        "    return binary_f1\r\n",
        "\r\n",
        "  def reset_states(self):\r\n",
        "    self.tp.assign(0)\r\n",
        "    self.fp.assign(0)\r\n",
        "    self.tn.assign(0)\r\n",
        "    self.fn.assign(0)\r\n",
        "\r\n",
        "class MusicF1(tf.keras.metrics.Metric):\r\n",
        "\r\n",
        "  def __init__(self, name='music_f1', **kwargs):\r\n",
        "    super(MusicF1, self).__init__(name=name, **kwargs)\r\n",
        "    self.tp = self.add_weight(name='true_positive', initializer='zeros')\r\n",
        "    self.fp = self.add_weight(name='false_positive', initializer='zeros')\r\n",
        "    self.tn = self.add_weight(name='true_negative', initializer='zeros')\r\n",
        "    self.fn = self.add_weight(name='false_negative', initializer='zeros')\r\n",
        "\r\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
        "\r\n",
        "    threshold = tf.constant([0.5])\r\n",
        "\r\n",
        "    binary_true = y_true[:, :, 1]\r\n",
        "    binary_pred = y_pred[:, :, 1]\r\n",
        "\r\n",
        "    binary_true = tf.greater_equal(binary_true, threshold)\r\n",
        "    binary_pred = tf.greater_equal(binary_pred, threshold)\r\n",
        "\r\n",
        "    tp = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, True)), dtype = np.float32)\r\n",
        "    fp = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, True)), dtype = np.float32)\r\n",
        "    tn = tf.cast(tf.logical_and(tf.equal(binary_true, False), tf.equal(binary_pred, False)), dtype = np.float32)\r\n",
        "    fn = tf.cast(tf.logical_and(tf.equal(binary_true, True), tf.equal(binary_pred, False)), dtype = np.float32)\r\n",
        "\r\n",
        "    self.tp.assign_add(tf.reduce_sum(tp, axis = None))\r\n",
        "    self.fp.assign_add(tf.reduce_sum(fp, axis = None))\r\n",
        "    self.tn.assign_add(tf.reduce_sum(tn, axis = None))\r\n",
        "    self.fn.assign_add(tf.reduce_sum(fn, axis = None))\r\n",
        "\r\n",
        "  def result(self):\r\n",
        "    binary_f1 = self.tp / (self.tp +  0.5 * (self.fp + self.fn))\r\n",
        "    return binary_f1\r\n",
        "\r\n",
        "  def reset_states(self):\r\n",
        "    self.tp.assign(0)\r\n",
        "    self.fp.assign(0)\r\n",
        "    self.tn.assign(0)\r\n",
        "    self.fn.assign(0)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5zSfg4eX76"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm2jZKzzkPtU"
      },
      "source": [
        "\"\"\"\r\n",
        "'test_audio_dir' is the directory of audio files\r\n",
        "\"\"\"\r\n",
        "test_audio_dir = \"/content/train-synth-audio-seg/Synthetic Radio Examples\"\r\n",
        "test_audio = glob.glob(test_audio_dir + \"/*.wav\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7ekT3_ceZsC",
        "outputId": "e5badfe1-1c98-4169-d83c-119ad8b98d23"
      },
      "source": [
        "\"\"\"\r\n",
        "This code block performs ensemble prediction for the final experiment of the MDPI paper ..\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "expt_seeds = [13, 29, 77, 8, 136]\r\n",
        "train_set_types = [\"ARE-RRE\", \"SSE-RRE\", \"SSE\"]\r\n",
        "\r\n",
        "# for train_set_type in train_set_types:\r\n",
        "#   models = []\r\n",
        "#   for expt_seed in expt_seeds:\r\n",
        "\r\n",
        "#     m = tf.keras.models.load_model(\"/content/drive/MyDrive/Post-ICASSP 2021/Experiments/MDPI Experiments/ARE-RRE-SSE/Seed\" + \r\n",
        "#                                   str(expt_seed) +\"/\"+ train_set_type + \"/model-best.h5\",\r\n",
        "#                                       custom_objects={'SpeechF1':SpeechF1(), 'MusicF1':MusicF1()})\r\n",
        "#     models.append(m)\r\n",
        "\r\n",
        "\r\n",
        "#   print(models)\r\n",
        "\r\n",
        "#   eval_path = \"/content/drive/MyDrive/Post-ICASSP 2021/Experiments/MDPI Experiments/ARE-RRE-SSE/Ensemble OpenBMAT\"\r\n",
        "\r\n",
        "#   ccc = 0\r\n",
        "  \r\n",
        "\r\n",
        "#   for tt in test_audio:\r\n",
        "#     ccc += 1\r\n",
        "#     if(ccc % 20 == 0):\r\n",
        "#       print(\"{} complete...\".format(ccc))\r\n",
        "\r\n",
        "#     ss, _ = sf.read(tt)\r\n",
        "#     oop = mk_preds_ens(tt)\r\n",
        "\r\n",
        "#     #print(oop.shape)\r\n",
        "#     p_smooth = smooth_output(oop.T, min_speech = 0.8, min_music = 3.4, max_silence_speech = 0.8, max_silence_music = 0.8)\r\n",
        "#     p_smooth = p_smooth.T\r\n",
        "#     see = preds_to_se(p_smooth, audio_clip_length=ss.shape[0]/22050.0)\r\n",
        "#     #print(see)\r\n",
        "#     n_label = tt.replace(\".wav\", \"-se-prediction.txt\")\r\n",
        "\r\n",
        "#     with open(n_label, 'w') as fp:\r\n",
        "#       fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))\r\n",
        "\r\n",
        "#   \"\"\"\r\n",
        "#   Code for second round of using sed_eval starts here.. This simply tests on one of the muspeak datasets\r\n",
        "#   \"\"\"\r\n",
        "\r\n",
        "#   se_dir = '/content/drive/My Drive/Data Synthesis/SE Audio Examples'\r\n",
        "#   n = 512\r\n",
        "\r\n",
        "#   file_list = [\r\n",
        "#       {\r\n",
        "#       'reference_file': tt.replace(\".wav\", \".txt\"),\r\n",
        "#       'estimated_file': tt.replace(\".wav\", \"-se-prediction.txt\")\r\n",
        "#       }\r\n",
        "#       for tt in test_audio\r\n",
        "#   ]\r\n",
        "\r\n",
        "#   data = []\r\n",
        "\r\n",
        "#   # Get used event labels\r\n",
        "#   all_data = dcase_util.containers.MetaDataContainer()\r\n",
        "#   for file_pair in file_list:\r\n",
        "#       reference_event_list = sed_eval.io.load_event_list(\r\n",
        "#           filename=file_pair['reference_file']\r\n",
        "#       )\r\n",
        "#       estimated_event_list = sed_eval.io.load_event_list(\r\n",
        "#           filename=file_pair['estimated_file']\r\n",
        "#       )\r\n",
        "\r\n",
        "#       data.append({'reference_event_list': reference_event_list,\r\n",
        "#                   'estimated_event_list': estimated_event_list})\r\n",
        "\r\n",
        "#       all_data += reference_event_list\r\n",
        "\r\n",
        "#   event_labels = all_data.unique_event_labels\r\n",
        "\r\n",
        "#   # Start evaluating\r\n",
        "\r\n",
        "#   # Create metrics classes, define parameters\r\n",
        "#   segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\r\n",
        "#       event_label_list=event_labels,\r\n",
        "#       time_resolution=0.010\r\n",
        "#   )\r\n",
        "\r\n",
        "#   event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\r\n",
        "#       event_label_list=event_labels,\r\n",
        "#       t_collar=0.500\r\n",
        "#   )\r\n",
        "\r\n",
        "#   # Go through files\r\n",
        "#   for file_pair in data:\r\n",
        "#       segment_based_metrics.evaluate(\r\n",
        "#           reference_event_list=file_pair['reference_event_list'],\r\n",
        "#           estimated_event_list=file_pair['estimated_event_list']\r\n",
        "#       )\r\n",
        "\r\n",
        "#       event_based_metrics.evaluate(\r\n",
        "#           reference_event_list=file_pair['reference_event_list'],\r\n",
        "#           estimated_event_list=file_pair['estimated_event_list']\r\n",
        "#       )\r\n",
        "\r\n",
        "#   # Get only certain metrics\r\n",
        "#   overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\r\n",
        "#   print(\"Accuracy:\", overall_segment_based_metrics['accuracy']['accuracy'])\r\n",
        "\r\n",
        "#   # Or print all metrics as reports\r\n",
        "\r\n",
        "#   model_basename = train_set_type\r\n",
        "#   seg_eval_basename = \"seg eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\r\n",
        "#   ev_eval_basename = \"event eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\r\n",
        "#   with open(os.path.join(eval_path, seg_eval_basename), mode='w') as fp:\r\n",
        "#     fp.write(str(segment_based_metrics))\r\n",
        "\r\n",
        "#   with open(eval_path + \"/seg eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\r\n",
        "#     pickle.dump(segment_based_metrics, f, pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "#   with open(os.path.join(eval_path, ev_eval_basename), mode = 'w') as fp:\r\n",
        "#     fp.write(str(event_based_metrics))\r\n",
        "\r\n",
        "#   with open(eval_path + \"/event eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\r\n",
        "#     pickle.dump(event_based_metrics, f, pickle.HIGHEST_PROTOCOL)   \r\n",
        "\r\n",
        "\r\n",
        "train_set_type = \"ARE\"\r\n",
        "# models = []\r\n",
        "\r\n",
        "# for expt_seed in expt_seeds:\r\n",
        "\r\n",
        "#   m = tf.keras.models.load_model(\"/content/train-synth-audio-seg/models/Seed\" + \r\n",
        "#                                 str(expt_seed) +\"/\"+ train_set_type + \"/model-best.h5\",\r\n",
        "#                                     custom_objects={'SpeechF1':SpeechF1(), 'MusicF1':MusicF1()})\r\n",
        "#   models.append(m)\r\n",
        "\r\n",
        "\r\n",
        "print(models)\r\n",
        "\r\n",
        "\r\n",
        "ccc = 0\r\n",
        "\r\n",
        "\r\n",
        "for tt in test_audio:\r\n",
        "  ccc += 1\r\n",
        "  if(ccc % 20 == 0):\r\n",
        "    print(\"{} complete...\".format(ccc))\r\n",
        "\r\n",
        "  ss, _ = sf.read(tt)\r\n",
        "  oop = mk_preds_ens(tt)\r\n",
        "\r\n",
        "  #print(oop.shape)\r\n",
        "  p_smooth = smooth_output(oop.T, min_speech = 0.8, min_music = 3.4, max_silence_speech = 0.8, max_silence_music = 0.8)\r\n",
        "  p_smooth = p_smooth.T\r\n",
        "  print(\"p_smooth shape is {}\".format(p_smooth.shape))\r\n",
        "  see = preds_to_se(p_smooth, audio_clip_length=ss.shape[0]/22050.0)\r\n",
        "  #print(see)\r\n",
        "  n_label = tt.replace(\".wav\", \"-se-prediction.txt\")\r\n",
        "\r\n",
        "  with open(n_label, 'w') as fp:\r\n",
        "    fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))\r\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.engine.functional.Functional object at 0x7f12e0da22d0>, <tensorflow.python.keras.engine.functional.Functional object at 0x7f12e0d996d0>, <tensorflow.python.keras.engine.functional.Functional object at 0x7f12e5584ed0>, <tensorflow.python.keras.engine.functional.Functional object at 0x7f12e40b8c10>, <tensorflow.python.keras.engine.functional.Functional object at 0x7f12d91f6fd0>]\n",
            "1\n",
            "p_smooth shape is (802, 2)\n",
            "1\n",
            "p_smooth shape is (802, 2)\n",
            "1\n",
            "p_smooth shape is (802, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM4nfodLeh5O"
      },
      "source": [
        "# Code to evaluate predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7DU-1NjelXa",
        "outputId": "5a33ecc7-6d85-4d63-e69c-c663d927db1a"
      },
      "source": [
        "\"\"\"\r\n",
        "Code for second round of using sed_eval starts here.. This simply tests on one of the muspeak datasets\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "eval_path = os.path.join(test_audio_dir, \"Eval\")\r\n",
        "\r\n",
        "try: \r\n",
        "  os.makedirs(eval_path, exist_ok = True) \r\n",
        "  print(\"Directory '%s' created successfully\" %eval_path) \r\n",
        "except OSError as error: \r\n",
        "    print(\"Directory '%s' already exists\")\r\n",
        "\r\n",
        "\r\n",
        "file_list = [\r\n",
        "    {\r\n",
        "    'reference_file': tt.replace(\".wav\", \"-label.txt\"),\r\n",
        "    'estimated_file': tt.replace(\".wav\", \"-se-prediction.txt\")\r\n",
        "    }\r\n",
        "    for tt in test_audio\r\n",
        "]\r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "# Get used event labels\r\n",
        "all_data = dcase_util.containers.MetaDataContainer()\r\n",
        "for file_pair in file_list:\r\n",
        "    reference_event_list = sed_eval.io.load_event_list(\r\n",
        "        filename=file_pair['reference_file']\r\n",
        "    )\r\n",
        "    estimated_event_list = sed_eval.io.load_event_list(\r\n",
        "        filename=file_pair['estimated_file']\r\n",
        "    )\r\n",
        "\r\n",
        "    data.append({'reference_event_list': reference_event_list,\r\n",
        "                'estimated_event_list': estimated_event_list})\r\n",
        "\r\n",
        "    all_data += reference_event_list\r\n",
        "\r\n",
        "event_labels = all_data.unique_event_labels\r\n",
        "\r\n",
        "# Start evaluating\r\n",
        "\r\n",
        "# Create metrics classes, define parameters\r\n",
        "segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\r\n",
        "    event_label_list=event_labels,\r\n",
        "    time_resolution=0.010\r\n",
        ")\r\n",
        "\r\n",
        "event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\r\n",
        "    event_label_list=event_labels,\r\n",
        "    t_collar=0.500\r\n",
        ")\r\n",
        "\r\n",
        "# Go through files\r\n",
        "for file_pair in data:\r\n",
        "    segment_based_metrics.evaluate(\r\n",
        "        reference_event_list=file_pair['reference_event_list'],\r\n",
        "        estimated_event_list=file_pair['estimated_event_list']\r\n",
        "    )\r\n",
        "\r\n",
        "    event_based_metrics.evaluate(\r\n",
        "        reference_event_list=file_pair['reference_event_list'],\r\n",
        "        estimated_event_list=file_pair['estimated_event_list']\r\n",
        "    )\r\n",
        "\r\n",
        "# Get only certain metrics\r\n",
        "overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\r\n",
        "print(\"Accuracy:\", overall_segment_based_metrics['accuracy']['accuracy'])\r\n",
        "\r\n",
        "# Or print all metrics as reports\r\n",
        "\r\n",
        "model_basename = train_set_type\r\n",
        "seg_eval_basename = \"seg eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\r\n",
        "ev_eval_basename = \"event eval \" + model_basename.replace(\".h5\", \"\") + \".txt\"\r\n",
        "with open(os.path.join(eval_path, seg_eval_basename), mode='w') as fp:\r\n",
        "  fp.write(str(segment_based_metrics))\r\n",
        "\r\n",
        "with open(eval_path + \"/seg eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\r\n",
        "  pickle.dump(segment_based_metrics, f, pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "with open(os.path.join(eval_path, ev_eval_basename), mode = 'w') as fp:\r\n",
        "  fp.write(str(event_based_metrics))\r\n",
        "\r\n",
        "with open(eval_path + \"/event eval \" + model_basename.replace(\".h5\", \"\") + \".pickle\", 'wb') as f:\r\n",
        "  pickle.dump(event_based_metrics, f, pickle.HIGHEST_PROTOCOL)   \r\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory '/content/train-synth-audio-seg/Synthetic Radio Examples/Eval' created successfully\n",
            "Accuracy: 0.9858333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQqYvAqGopaY",
        "outputId": "74273621-7cce-413e-9efd-ec9bc969d93a"
      },
      "source": [
        "test_audio"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train-synth-audio-seg/Synthetic Radio Examples/example-1.wav',\n",
              " '/content/train-synth-audio-seg/Synthetic Radio Examples/example-3.wav',\n",
              " '/content/train-synth-audio-seg/Synthetic Radio Examples/example-2.wav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLt9J0tloPB9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}